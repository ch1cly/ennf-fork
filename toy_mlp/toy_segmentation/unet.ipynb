{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspaces/ennf-fork/toy_mlp/toy_segmentation',\n",
       " '/home/codespace/.python/current/lib/python310.zip',\n",
       " '/home/codespace/.python/current/lib/python3.10',\n",
       " '/home/codespace/.python/current/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/home/codespace/.local/lib/python3.10/site-packages',\n",
       " '/home/codespace/.python/current/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/workspaces/ennf-fork')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from nn_lib.mdl.loss_functions import CELoss, BCELoss_logits\n",
    "from nn_lib.optim import Adam, Optimizer\n",
    "from nn_lib.data import Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from toy_mlp.toy_segmentation.model_trainer import UNetTrainer\n",
    "from toy_mlp.mnist_classifier.mnist_mlp_classifier import MnistMLPClassifier\n",
    "from toy_mlp.toy_segmentation.unet import UNet\n",
    "from toy_mlp.toy_segmentation.small_unet import SmallUNet\n",
    "from toy_mlp.toy_segmentation.small_unet_1 import SmallUNet1\n",
    "from toy_mlp.history_plotter import plot_loss\n",
    "from toy_mlp.toy_segmentation.PH2_dataset import PH2\n",
    "\n",
    "from nn_lib.scheduler.multi_step_lr import MultiStepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn_lib.support_func import iou_score\n",
    "from nn_lib import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = val_dataset.labels[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16, 16, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('bool')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = a.copy()\n",
    "b1[:,:,7:] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_score(Tensor(a,requires_grad=False),Tensor(b1,requires_grad=False)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs=10\n",
    "optim: Optimizer = Adam\n",
    "batch_size=25\n",
    "milestones=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/ennf-fork/toy_mlp/toy_segmentation/PH2Dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/ennf-fork/toy_mlp/toy_segmentation/PH2Dataset\n"
     ]
    }
   ],
   "source": [
    "# generate a training dataset\n",
    "size = (16,16)\n",
    "#size = (32,32)\n",
    "train_dataset = PH2(ds_type='train',size=size)\n",
    "# generate a validation dataset different from the training dataset\n",
    "val_dataset = PH2(ds_type='val',size=size)\n",
    "# create a dataloader for training data with shuffling and dropping last batch\n",
    "train_dataloader = Dataloader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "# create a dataloader for validation dataset without shuffling or last batch dropping\n",
    "val_dataloader = Dataloader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created the following binary MLP classifier:\n",
      "[<nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f0487e3fdc0>, <nn_lib.mdl.layers.relu.Relu object at 0x7f046f10d3f0>, <nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f046f10f1f0>, <nn_lib.mdl.layers.relu.Relu object at 0x7f046dae9a20>]\n",
      "[<nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f0487e3fc10>, <nn_lib.mdl.layers.relu.Relu object at 0x7f0487e3f9a0>, <nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f0487e23280>, <nn_lib.mdl.layers.relu.Relu object at 0x7f0487e22110>]\n",
      "[<nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f0487e23940>, <nn_lib.mdl.layers.relu.Relu object at 0x7f0487e22da0>, <nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f0487e23490>, <nn_lib.mdl.layers.relu.Relu object at 0x7f0487e234c0>]\n",
      "[<nn_lib.mdl.layers.convolution_2d.Conv2d object at 0x7f0487e23eb0>]\n",
      "Total number of parameters: 223873\n"
     ]
    }
   ],
   "source": [
    "mlp_model = SmallUNet1(kernum=64)\n",
    "print(f'Created the following binary MLP classifier:\\n{mlp_model}')\n",
    "# create loss function\n",
    "loss_fn = BCELoss_logits() #CELoss()\n",
    "# create optimizer for model parameters\n",
    "optimizer = optim(mlp_model.parameters(), lr=1e-2, weight_decay=5e-4)\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones, gamma=0.5)\n",
    "# create a model trainer\n",
    "model_trainer = UNetTrainer(mlp_model, loss_fn, optimizer, scheduler=scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "model_trainer.set_datasets(train_dataloader, val_dataloader)\n",
    "model_trainer.train(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
